# Tokymon Project - Complete Summary

## ğŸ“ Complete Folder Structure

```
tokymon/
â”œâ”€â”€ brain/                          # AI/LLM integration layer
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ intent_parser.py           # Parses user intents from speech/text
â”‚   â”œâ”€â”€ llm_gateway.py             # LLM API integration (OpenAI, etc.)
â”‚   â”œâ”€â”€ policy_engine.py           # Safety policy enforcement
â”‚   â””â”€â”€ state_manager.py           # Robot state management
â”‚
â”œâ”€â”€ configs/                        # Configuration files (YAML)
â”‚   â”œâ”€â”€ env.dev.yaml               # Development environment config
â”‚   â”œâ”€â”€ env.prod.yaml              # Production environment config
â”‚   â”œâ”€â”€ pinmap_pi.yaml             # Hardware pin mappings (BCM GPIO)
â”‚   â””â”€â”€ services.yaml              # Service configurations (LLM, STT, TTS, MQTT)
â”‚
â”œâ”€â”€ control/                        # Motor and actuator control
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ actuators.py               # Actuator abstractions
â”‚   â”œâ”€â”€ motors.py                  # TB6612 motor driver (forward, backward, turn)
â”‚   â”œâ”€â”€ pwm_helpers.py             # PWM control utilities
â”‚   â””â”€â”€ safety.py                  # Safety manager with watchdog timers
â”‚
â”œâ”€â”€ data/                           # Runtime data storage
â”‚   â”œâ”€â”€ photos/                    # Camera capture outputs
â”‚   â””â”€â”€ reports/                   # Hardware test reports (JSON)
â”‚
â”œâ”€â”€ display/                        # LED matrix display (MAX7219)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ expressions.py            # Face expressions (eyes, mouth, animations)
â”‚   â””â”€â”€ max7219_driver.py         # SPI driver with auto-detection & image rotation
â”‚
â”œâ”€â”€ drivers/                        # Low-level hardware drivers
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ rpi_gpio.py               # GPIO abstraction (SafeGPIO for Pi 5)
â”‚   â”œâ”€â”€ safe_gpio.py              # SafeGPIO wrapper (lgpio for Pi 5)
â”‚   â””â”€â”€ sysfs_gpio.py             # Sysfs GPIO backend (legacy)
â”‚
â”œâ”€â”€ examples/                       # Example scripts and hardware tests
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ demo_read_sensors.py      # Simple sensor reading demo
â”‚   â”œâ”€â”€ demo_speech_move.py       # Speech-to-movement demo
â”‚   â”œâ”€â”€ full_hw_test.py           # Complete hardware auto-test (LED, audio, camera, sensors, motors)
â”‚   â”œâ”€â”€ hw_test.py                # Basic hardware test
â”‚   â””â”€â”€ hw_test_helpers.py        # Test utilities
â”‚
â”œâ”€â”€ models/                         # ML models (placeholder)
â”‚
â”œâ”€â”€ prompts/                        # LLM prompt templates
â”‚   â”œâ”€â”€ intent_to_action.tpl      # Intent parsing prompt
â”‚   â””â”€â”€ system_prompt.txt         # System context for LLM
â”‚
â”œâ”€â”€ raw_scripts/                    # Original working scripts (reference)
â”‚   â”œâ”€â”€ ir_detect_5s_led.py       # IR sensor + LED test
â”‚   â”œâ”€â”€ toky_voice.py             # Voice synthesis test
â”‚   â”œâ”€â”€ tokymon_dual_control.py   # Dual motor control test
â”‚   â”œâ”€â”€ tokymon_max7219_faces_round_eyes_central.py  # Face expressions
â”‚   â””â”€â”€ ultrasonic_test.py        # HC-SR04 ultrasonic test
â”‚
â”œâ”€â”€ scripts/                        # Deployment and utility scripts
â”‚   â”œâ”€â”€ deploy_to_pi.sh           # Deploy code to Raspberry Pi
â”‚   â”œâ”€â”€ full_hw_test_run.sh       # Run full hardware test
â”‚   â”œâ”€â”€ hw_test_run.sh            # Run basic hardware test
â”‚   â”œâ”€â”€ install_requirements.sh   # Install Python dependencies
â”‚   â”œâ”€â”€ run_tokymon.sh            # Main entrypoint script
â”‚   â”œâ”€â”€ setup_venv.sh             # Virtual environment setup
â”‚   â””â”€â”€ tokymon.service           # Systemd service file
â”‚
â”œâ”€â”€ sensors/                        # Sensor drivers and interface
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ interface.py              # Sensor interface abstraction
â”‚   â”œâ”€â”€ simulator.py              # Simulator mode for sensors
â”‚   â””â”€â”€ drivers/
â”‚       â”œâ”€â”€ hcsr04.py             # HC-SR04 ultrasonic sensor (Pi 5 compatible)
â”‚       â”œâ”€â”€ ir_left.py            # Left IR sensor
â”‚       â”œâ”€â”€ ir_right.py           # Right IR sensor
â”‚       â””â”€â”€ ir_sensor.py          # IR sensor interface
â”‚
â”œâ”€â”€ system/                         # Core system utilities
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                 # Centralized config loader (YAML + .env)
â”‚   â”œâ”€â”€ logger.py                 # Logging setup
â”‚   â”œâ”€â”€ mqtt_bus.py               # MQTT message bus (with simulator mock)
â”‚   â””â”€â”€ supervisor.py             # System supervisor
â”‚
â”œâ”€â”€ tests/                          # Test suite
â”‚   â”œâ”€â”€ integration/
â”‚   â”‚   â”œâ”€â”€ test_hw_flow_simulator.py  # Hardware flow integration test
â”‚   â”‚   â””â”€â”€ test_mqtt_flow.py          # MQTT integration test
â”‚   â””â”€â”€ unit/
â”‚       â”œâ”€â”€ test_hcsr04.py        # Ultrasonic sensor unit test
â”‚       â”œâ”€â”€ test_motors.py        # Motor driver unit test
â”‚       â”œâ”€â”€ test_mqtt_config.py   # MQTT config test
â”‚       â””â”€â”€ test_mqtt_mock.py     # MQTT mock test
â”‚
â”œâ”€â”€ tools/                          # Utility tools
â”‚   â””â”€â”€ calibrate_hcsr04.py       # Ultrasonic sensor calibration
â”‚
â”œâ”€â”€ vision/                         # Camera and vision processing
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ camera.py                 # Camera capture (libcamera/rpicam)
â”‚
â”œâ”€â”€ voice/                          # Speech input/output
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ audio.py                  # Audio I/O utilities
â”‚   â”œâ”€â”€ stt.py                    # Speech-to-text (Whisper, etc.)
â”‚   â””â”€â”€ tts.py                    # Text-to-speech (espeak + aplay)
â”‚
â”œâ”€â”€ voice_prompts/                  # Voice prompt templates
â”‚
â”œâ”€â”€ main.py                         # Main entrypoint
â”œâ”€â”€ README.md                       # Project documentation
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ pyproject.toml                  # Project metadata
â””â”€â”€ LICENSE                         # License file
```

---

## ğŸ¯ What We've Built

### **Tokymon** - A Raspberry Pi 5 Robot Framework

A complete, production-ready robot control framework with:
- **Hardware abstraction** for sensors, motors, displays, audio, and camera
- **Simulator mode** for development without hardware
- **Safety-first design** with watchdog timers and policy enforcement
- **Config-driven architecture** for easy customization
- **Comprehensive hardware testing** suite

---

## ğŸ”§ What We've Done & Why

### 1. **Project Structure & Configuration System**

**Files Created:**
- `system/config.py` - Centralized configuration loader
- `configs/pinmap_pi.yaml` - Hardware pin mappings
- `configs/services.yaml` - Service configurations
- `configs/env.dev.yaml` & `configs/env.prod.yaml` - Environment-specific configs

**Why:**
- **Single source of truth** for all hardware pins and settings
- **Environment-aware** (dev vs prod) for simulator vs real hardware
- **Easy deployment** - change configs without code changes
- **Path detection** - automatically detects Mac dev vs Pi production paths

**Key Features:**
- Loads YAML configs with deep merging
- Reads `.env` files for secrets (API keys)
- Auto-detects root path (`/Users/ankursharma/Documents/Dev Projects/tokymon` on Mac, `/home/ankursharma/Projects/tokymon` on Pi)

---

### 2. **Raspberry Pi 5 GPIO Compatibility**

**Files Modified:**
- `drivers/rpi_gpio.py` - GPIO abstraction layer
- `drivers/safe_gpio.py` - SafeGPIO wrapper using `lgpio`
- `drivers/sysfs_gpio.py` - Sysfs backend (legacy)

**Why:**
- **Raspberry Pi 5 is NOT compatible with RPi.GPIO** (legacy library)
- Pi 5 uses new GPIO chip architecture requiring `lgpio` library
- **Global GPIO offset** needed: BCM pin + 559 (or 569) = global GPIO number

**Solution:**
- Always use `SafeGPIO` backend (lgpio-based) for Pi 5
- Convert BCM pins to global GPIO numbers automatically
- Fallback to sysfs for older Pi models
- Simulator mode uses no-op mocks

**Example:**
```python
# BCM pin 23 â†’ Global GPIO 582 (23 + 559)
# BCM pin 24 â†’ Global GPIO 583 (24 + 559)
```

---

### 3. **Motor Driver: L298 â†’ TB6612 Migration**

**Files Modified:**
- `control/motors.py` - Complete rewrite for TB6612 driver
- `configs/pinmap_pi.yaml` - Updated pin mappings
- `tests/unit/test_motors.py` - Updated unit tests

**Why:**
- **TB6612 is more efficient** than L298 (lower power consumption, better PWM control)
- **Smaller form factor** - better for compact robots
- **Built-in protection** - thermal shutdown, overcurrent protection

**Key Changes:**
- Replaced L298 pin structure with TB6612 (AIN1, AIN2, BIN1, BIN2, PWMA, PWMB, STBY)
- Fixed polarity issues (motor A direction inverted)
- Uses `lgpio` for PWM control (Pi 5 compatible)
- Maintains same public API: `forward()`, `backward()`, `turn_left()`, `turn_right()`, `stop()`

**Pin Mapping:**
- Motor A: AIN1=5, AIN2=6, PWMA=12
- Motor B: BIN1=20, BIN2=21, PWMB=13
- Standby: STBY=22

---

### 4. **Ultrasonic Sensor (HC-SR04) - Pi 5 Compatible**

**Files Modified:**
- `sensors/drivers/hcsr04.py` - Complete rewrite
- `sensors/interface.py` - Updated interface

**Why:**
- **Pi 5 GPIO changes** require global GPIO numbers, not BCM
- **Voltage divider** needed for 5V echo signal â†’ 3.3V Pi input
- **Timing precision** critical for accurate distance measurement

**Solution:**
- Uses global GPIO numbers (582, 583) instead of BCM (23, 24)
- Proper timing with `time.sleep()` and `time.time()` for pulse measurement
- Simulator mode returns mock distances
- Error handling for timeout/no-echo scenarios

**Formula:**
```
Distance (cm) = (pulse_duration_us / 2) / 29.1
```

---

### 5. **LED Matrix Display (MAX7219) - Robust Text Rendering**

**Files Modified:**
- `display/max7219_driver.py` - Complete rewrite with image rotation
- `display/expressions.py` - Face expression animations (unchanged)

**Why:**
- **Text was cut off or upside-down** due to orientation issues
- **LUMA block_orientation** doesn't work well for all setups
- **Need robust rendering** that works regardless of physical mounting

**Solution:**
- **Auto-detects SPI device** (`/dev/spidev0.0`, `/dev/spidev0.1`, `/dev/spidev10.0`)
- **Image rotation pipeline:**
  1. Create horizontal Pillow image with text
  2. Text origin at `(device_width + X_OFFSET, centered vertically)`
  3. Rotate entire image by `ORIENTATION` (0, 90, 180, 270)
  4. Scroll rotated image across display
- **Config-driven:** `cascaded`, `orientation`, `scroll_speed`, `x_offset` from config
- **Always uses `block_orientation=0`** - rotation handled via image rotation

**Config Example:**
```yaml
board_options:
  led_matrix:
    cascaded: 4
    orientation: 180
    scroll_speed: 0.03
    x_offset: 0
```

---

### 6. **Audio System - Fixed Device Configuration**

**Files Modified:**
- `examples/full_hw_test.py` - Fixed mic/speaker devices
- `voice/tts.py` - Fixed speaker device

**Why:**
- **Audio devices were unreliable** - default device detection failed
- **Error 524** from `aplay` - device not accessible
- **Need consistent audio I/O** for voice commands and responses

**Solution:**
- **Fixed microphone:** `plughw:1,0` (USB mic)
- **Fixed speaker:** `plughw:3,0` (USB speaker/amp)
- **Environment variable override:** `AUDIO_PLAYBACK` for speaker device
- **Fallback logic:** Try fixed device, then default, then list available devices
- **Recording duration:** Fixed to 5 seconds for hardware test

**Audio Flow:**
1. Record 5 seconds from `plughw:1,0` â†’ `/tmp/tokymon_test.wav`
2. Play back on `plughw:3,0` (or `$AUDIO_PLAYBACK` if set)
3. Log device used before playback

---

### 7. **Camera Integration - rpicam-still Support**

**Files Modified:**
- `examples/full_hw_test.py` - Camera capture with rotation

**Why:**
- **Raspberry Pi 5 uses `rpicam-still`** instead of `libcamera-still`
- **Camera orientation** - images upside-down need 180Â° rotation
- **Binary detection** - need to find correct camera command

**Solution:**
- **Priority order:** `rpicam-still` â†’ `libcamera-still` â†’ `raspistill`
- **Auto-detection:** Checks common paths (`/usr/bin/rpicam-still`, etc.)
- **Image rotation:** After capture, rotate 180Â° using PIL
- **Troubleshooting:** Detailed error messages with fix steps

**Camera Flow:**
1. Try `rpicam-still -o photo.jpg -t 1000`
2. If successful, rotate image 180Â° with PIL
3. Save to `data/temp/tokymon_photo.jpg`
4. Show on LED display: "PHOTO" + success expression

---

### 8. **Hardware Test Suite - Comprehensive Auto-Test**

**Files Created/Modified:**
- `examples/full_hw_test.py` - Complete hardware test flow
- `scripts/full_hw_test_run.sh` - Test runner script

**Why:**
- **Need automated validation** of all hardware components
- **Troubleshooting guide** for common issues
- **Simulator mode** for development without hardware

**Test Flow:**
1. **LED Matrix** - Show "TOKYMON", expressions, clear
2. **Audio** - Record 5s, play back on fixed devices
3. **Camera** - Capture photo, rotate 180Â°, display
4. **IR Sensors** - Read left/right obstacle detection
5. **Ultrasonic** - Measure distance (cm)
6. **Motors** - Forward, backward, turn left, turn right, stop
7. **Final Display** - Show "OK" on LED matrix

**Features:**
- **Simulator mode:** Logs actions without hardware access
- **Error handling:** Detailed troubleshooting steps
- **Temp directory:** Auto-detects writable temp location
- **Device detection:** Auto-finds audio/camera devices

---

### 9. **Safety System**

**Files Created:**
- `control/safety.py` - Safety manager with watchdog

**Why:**
- **Prevent runaway motors** - emergency stop if software crashes
- **Policy enforcement** - only allow safe movement commands
- **Heartbeat monitoring** - detect if main loop stops responding

**Features:**
- **Watchdog timer:** Stops motors if heartbeat missed
- **Policy engine:** Whitelist of allowed actions
- **Duration limits:** Max movement time enforced
- **Emergency stop:** Immediate motor shutdown

---

### 10. **Simulator Mode - Development Without Hardware**

**Files Created:**
- `sensors/simulator.py` - Sensor simulators

**Why:**
- **Develop on Mac** without Raspberry Pi hardware
- **Test logic** without physical components
- **CI/CD friendly** - tests run without hardware

**Implementation:**
- **Environment variable:** `TOKY_ENV=dev` enables simulator
- **Config flag:** `use_simulator: true` in `services.yaml`
- **Mock behavior:** All hardware calls log instead of execute
- **Realistic values:** Simulators return plausible sensor readings

**Example:**
```python
if USE_SIM:
    LOGGER.info("show_text(sim): TOKYMON")
    return  # Skip hardware access
```

---

### 11. **MQTT Message Bus**

**Files Created:**
- `system/mqtt_bus.py` - MQTT client with simulator mock

**Why:**
- **Inter-component communication** - sensors â†’ brain â†’ actuators
- **Remote control** - send commands via MQTT
- **Logging/telemetry** - publish sensor data

**Features:**
- **Simulator mode:** Mock MQTT client (logs to console)
- **Production:** Real MQTT broker connection
- **Topic prefix:** `tokymon/` for all topics
- **Auto-reconnect:** Handles connection failures

---

### 12. **Voice Integration (STT/TTS)**

**Files Created:**
- `voice/stt.py` - Speech-to-text (Whisper integration)
- `voice/tts.py` - Text-to-speech (espeak + aplay)
- `voice/audio.py` - Audio I/O utilities

**Why:**
- **Voice commands** - control robot via speech
- **Voice feedback** - robot speaks responses
- **Natural interaction** - more intuitive than buttons

**Implementation:**
- **STT:** Whisper model for speech recognition
- **TTS:** espeak for synthesis, aplay for playback
- **Fixed devices:** Mic `plughw:1,0`, Speaker `plughw:3,0`
- **Simulator:** Logs text instead of audio I/O

---

### 13. **Brain/LLM Integration**

**Files Created:**
- `brain/llm_gateway.py` - LLM API integration
- `brain/intent_parser.py` - Parse user intents
- `brain/policy_engine.py` - Safety policy enforcement
- `brain/state_manager.py` - Robot state tracking

**Why:**
- **Natural language commands** - "move forward", "turn left", etc.
- **Intent understanding** - convert speech to actions
- **Safety first** - policy engine blocks unsafe commands

**Flow:**
1. User speaks â†’ STT converts to text
2. Text â†’ LLM â†’ Intent (move, stop, etc.)
3. Intent â†’ Policy engine â†’ Allowed/Blocked
4. If allowed â†’ Execute action via motors/sensors

---

### 14. **Testing Infrastructure**

**Files Created:**
- `tests/unit/` - Unit tests for individual components
- `tests/integration/` - Integration tests for full flows

**Why:**
- **Verify correctness** - ensure code works as expected
- **Regression prevention** - catch bugs before deployment
- **Documentation** - tests show how to use components

**Test Coverage:**
- Motor driver (TB6612)
- Ultrasonic sensor (HC-SR04)
- MQTT bus (mock and real)
- Hardware flow (simulator mode)

---

### 15. **Deployment Scripts**

**Files Created:**
- `scripts/deploy_to_pi.sh` - Deploy code to Raspberry Pi
- `scripts/run_tokymon.sh` - Main entrypoint
- `scripts/tokymon.service` - Systemd service file
- `scripts/install_requirements.sh` - Install dependencies

**Why:**
- **Automated deployment** - push code to Pi easily
- **Service management** - auto-start on boot
- **Dependency management** - ensure all packages installed

---

## ğŸ¯ Key Design Decisions

### 1. **Config-Driven Architecture**
- **Why:** Easy to change hardware pins, services, behavior without code changes
- **How:** YAML configs + `.env` files for secrets

### 2. **Simulator Mode**
- **Why:** Develop and test on Mac without Raspberry Pi hardware
- **How:** Environment variable `TOKY_ENV=dev` + config flag `use_simulator: true`

### 3. **Hardware Abstraction**
- **Why:** Support different hardware (L298 vs TB6612, different sensors)
- **How:** Driver layer with consistent interfaces

### 4. **Safety First**
- **Why:** Prevent damage to robot or environment
- **How:** Policy engine + watchdog timers + emergency stop

### 5. **Pi 5 Compatibility**
- **Why:** Raspberry Pi 5 has different GPIO architecture
- **How:** Always use `SafeGPIO` (lgpio) + global GPIO offset conversion

---

## ğŸ“Š Current Status

### âœ… **Completed:**
- Project structure and configuration system
- GPIO abstraction (Pi 5 compatible)
- Motor driver (TB6612)
- Sensor drivers (IR, Ultrasonic)
- LED matrix display (MAX7219 with image rotation)
- Audio system (fixed devices)
- Camera integration (rpicam-still with rotation)
- Hardware test suite
- Simulator mode
- Safety system
- MQTT bus
- Voice integration (STT/TTS)
- Brain/LLM integration (scaffold)
- Testing infrastructure
- Deployment scripts

### ğŸ”„ **In Progress:**
- Real LLM provider integration (OpenAI API keys)
- Real STT provider integration (Whisper API)
- Real TTS provider integration (ElevenLabs API)

### ğŸ“ **TODO:**
- Validate on actual Raspberry Pi 5 hardware
- Fine-tune sensor calibrations
- Add more expressions/animations
- Implement advanced navigation logic
- Add MQTT topic handlers for remote control

---

## ğŸš€ How to Use

### **Development (Mac):**
```bash
cd "/Users/ankursharma/Documents/Dev Projects/tokymon"
export TOKY_ENV=dev
python3 main.py
```

### **Hardware Test (Pi):**
```bash
cd /home/ankursharma/Projects/tokymon
export TOKY_ENV=prod
./scripts/full_hw_test_run.sh
```

### **Run Tests:**
```bash
TOKY_ENV=dev PYTHONPATH=. pytest -q
```

---

## ğŸ“š Key Files Reference

| File | Purpose |
|------|---------|
| `main.py` | Main entrypoint |
| `system/config.py` | Configuration loader |
| `control/motors.py` | Motor control (TB6612) |
| `sensors/drivers/hcsr04.py` | Ultrasonic sensor |
| `display/max7219_driver.py` | LED matrix display |
| `examples/full_hw_test.py` | Complete hardware test |
| `voice/tts.py` | Text-to-speech |
| `brain/llm_gateway.py` | LLM integration |

---

## ğŸ”’ Security Notes

- **Never commit secrets** - `.env` files are gitignored
- **API keys** stored in `.env.local` (not in repo)
- **Simulator mode** safe for development (no hardware access)

---

## ğŸ“ Support

For issues or questions:
1. Check `README.md` for setup instructions
2. Run `examples/full_hw_test.py` for hardware diagnostics
3. Check logs in simulator mode for debugging

---

**Last Updated:** 2025-12-04
**Project Status:** âœ… Production-Ready Scaffold


